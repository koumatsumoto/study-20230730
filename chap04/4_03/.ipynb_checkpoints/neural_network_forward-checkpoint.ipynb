{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNetwork:    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_neurons,  # 入力層のニューロン数\n",
    "        hidden_neurons, # 隠れ層のニューロン数\n",
    "        output_neurons, # 出力層のニューロン数\n",
    "        learning_rate   # 学習率\n",
    "        ):\n",
    "        '''\n",
    "        ニューラルネットワークの初期化を行う\n",
    "\n",
    "        '''\n",
    "        # 入力層、隠れ層、出力層のニューロン数をインスタンス変数に代入\n",
    "        self.inneurons = input_neurons # 入力層のニューロン数\n",
    "        self.hneurons = hidden_neurons # 隠れ層のニューロン数\n",
    "        self.oneurons = output_neurons # 出力層のニューロン数\n",
    "        self.lr = learning_rate        # 学習率\n",
    "        self.weight_initializer()      # weight_initializer()を呼ぶ\n",
    "\n",
    "    def weight_initializer(self):\n",
    "        '''\n",
    "        重みとバイアスの初期化を行う\n",
    "        \n",
    "        '''\n",
    "        # 隠れ層の重みとバイアスを初期化\n",
    "        self.w1 = np.random.normal(\n",
    "            0.0,                       # 平均は0\n",
    "            pow(self.inneurons, -0.5), # 標準偏差は入力層のニューロン数を元に計算\n",
    "            (self.hneurons,            # 行数は隠れ層のニューロン数\n",
    "             self.inneurons + 1)       # 列数は入力層のニューロン数 + 1\n",
    "            )\n",
    "        \n",
    "       # 出力層の重みとバイアスを初期化\n",
    "        self.w2 = np.random.normal(\n",
    "            0.0,                      # 平均は0\n",
    "            pow(self.hneurons, -0.5), # 標準偏差は隠れ層のニューロン数を元に計算\n",
    "            (self.oneurons,           # 行数は出力層のニューロン数\n",
    "             self.hneurons + 1)       # 列数は隠れ層のニューロン数 + 1\n",
    "            )\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        '''\n",
    "        シグモイド関数\n",
    "        ------------------------\n",
    "        x : 関数を適用するデータ\n",
    "        '''\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        '''\n",
    "        ソフトマックス関数\n",
    "        ------------------------\n",
    "        x : 関数を適用するデータ\n",
    "        '''\n",
    "        c = np.max(x)\n",
    "        exp_x = np.exp(x - c) # オーバーフローを防止する\n",
    "        sum_exp_x = np.sum(exp_x)\n",
    "        y = exp_x / sum_exp_x\n",
    "        return y\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        '''\n",
    "        ニューラルネットワークの学習を行う\n",
    "        ------------------------\n",
    "        inputs_list  : 訓練データの配列\n",
    "        targets_list : 正解ラベルの配列\n",
    "        \n",
    "        '''\n",
    "        ## [入力層]\n",
    "        # 入力値の配列にバイアス項を追加して入力層から出力する\n",
    "        inputs = np.array(\n",
    "            np.append(\n",
    "                inputs_list, [1]), # 配列の末尾にバイアスのための「1」を追加\n",
    "            ndmin=2                # 2次元化\n",
    "        ).T                        # 転置して1列の行列にする\n",
    "\n",
    "        ## [隠れ層]\n",
    "        # 入力層の出力に重み、バイアスを適用して隠れ層に入力する\n",
    "        hidden_inputs = np.dot(\n",
    "            self.w1,              # 隠れ層の重み\n",
    "            inputs                # 入力層の出力\n",
    "            )\n",
    "        # 活性化関数を適用して隠れ層から出力\n",
    "        hidden_outputs = self.sigmoid(hidden_inputs)        \n",
    "        # 隠れ層の出力行列の末尾にバイアスのための「1」を追加\n",
    "        hidden_outputs = np.append(\n",
    "            hidden_outputs,      # 隠れ層の出力行列\n",
    "            [[1]],               # 2次元形式でバイアス値を追加\n",
    "            axis=0               # 行を指定(列は1)\n",
    "            )\n",
    "        \n",
    "        ## [出力層]\n",
    "        # 出力層への入力信号を計算\n",
    "        final_inputs = np.dot(\n",
    "            self.w2,             # 隠れ層と出力層の間の重み\n",
    "            hidden_outputs       # 隠れ層の出力\n",
    "            )\n",
    "        # 活性化関数を適用して出力層から出力する\n",
    "        final_outputs = self.softmax(final_inputs)\n",
    "        \n",
    "        ## ---バックプロパゲーション---(出力層)\n",
    "        # 正解ラベルの配列を1列の行列に変換する\n",
    "        targets = np.array(\n",
    "            targets_list,        # 正解ラベルの配列\n",
    "            ndmin=2              # 2次元化\n",
    "            ).T                  # 転置して1列の行列にする\n",
    "        # 出力値と正解ラベルとの誤差\n",
    "        output_errors = final_outputs - targets\n",
    "        # 出力層の入力誤差δを求める\n",
    "        delta_output = output_errors*(1 - final_outputs)*final_outputs\n",
    "        # 重みを更新する前に隠れ層の出力誤差を求めておく\n",
    "        hidden_errors = np.dot(\n",
    "            self.w2.T,           # 出力層の重み行列を転置する\n",
    "            delta_output         # 出力層の入力誤差δ\n",
    "            )\n",
    "        # 出力層の重み、バイアスの更新\n",
    "        self.w2 -= self.lr * np.dot(\n",
    "            # 出力誤差＊(1－出力信号)＊出力信号 \n",
    "            delta_output,\n",
    "            # 隠れ層の出力行列を転置\n",
    "            hidden_outputs.T\n",
    "        )\n",
    "        print(final_outputs)\n",
    "        print(sum(final_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23147895]\n",
      " [0.16219106]\n",
      " [0.60632999]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "in_neurons = 3      # 入力層のニューロンの数\n",
    "h_neuronss = 3      # 隠れ層のニューロンの数\n",
    "o_neurons = 3       # 出力層のニューロンの数\n",
    "learning_rate = 0.1 # 学習率\n",
    "\n",
    "# neuralNetworkオブジェクトの生成\n",
    "n = neuralNetwork(\n",
    "    in_neurons, h_neuronss, o_neurons, learning_rate)\n",
    "\n",
    "# ダミーの訓練データ\n",
    "inputs_list = [1.0, 1.5, 2.0]\n",
    "# ダミーの正解ラベル\n",
    "targets_list = [1.0, 1.5, 2.0]\n",
    "#train()を実行\n",
    "n.train(inputs_list, targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
